{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:22.381732Z",
     "start_time": "2024-04-23T17:43:19.870164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "!{sys.executable} -m pip install -q mediapipe==0.10.9 opencv-python"
   ],
   "id": "60517baadd5bde45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/youtube_dl-2021.12.17-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:23.042810Z",
     "start_time": "2024-04-23T17:43:22.385650Z"
    }
   },
   "cell_type": "code",
   "source": "!wget -q https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
   "id": "59571979d8111b5a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:24.533728Z",
     "start_time": "2024-04-23T17:43:23.048302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from matplotlib import pyplot as plt\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ],
   "id": "fe7e884b729f1bfc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:25.101753Z",
     "start_time": "2024-04-23T17:43:24.536044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMAGE_FILENAMES = ['thumbs_down.jpg', 'victory.jpg', 'thumbs_up.jpg', 'pointing_up.jpg']\n",
    "\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ],
   "id": "b0bef7dd709b02b9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:25.369168Z",
     "start_time": "2024-04-23T17:43:25.103216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  cv2.imshow('image', img)\n",
    "\n",
    "\n",
    "# Preview the images.\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "for name, image in images.items():\n",
    "  print(name)\n",
    "  resize_and_show(image)"
   ],
   "id": "4509ff7af173b848",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thumbs_down.jpg\n",
      "victory.jpg\n",
      "thumbs_up.jpg\n",
      "pointing_up.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 19:43:25.315 Python[75373:5123267] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/0n/6m4s0r5s7fv43yz5mqzx353w0000gn/T/org.python.python.savedState\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:25.382550Z",
     "start_time": "2024-04-23T17:43:25.371626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'xtick.labelbottom': False,\n",
    "    'xtick.bottom': False,\n",
    "    'ytick.labelleft': False,\n",
    "    'ytick.left': False,\n",
    "    'xtick.labeltop': False,\n",
    "    'xtick.top': False,\n",
    "    'ytick.labelright': False,\n",
    "    'ytick.right': False\n",
    "})\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "\n",
    "def display_one_image(image, title, subplot, titlesize=16):\n",
    "    \"\"\"Displays one image along with the predicted category name and score.\"\"\"\n",
    "    plt.subplot(*subplot)\n",
    "    plt.imshow(image)\n",
    "    if len(title) > 0:\n",
    "        plt.title(title, fontsize=int(titlesize), color='black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
    "    return (subplot[0], subplot[1], subplot[2]+1)\n",
    "\n",
    "\n",
    "def display_batch_of_images_with_gestures_and_hand_landmarks(images, results):\n",
    "    \"\"\"Displays a batch of images with the gesture category and its score along with the hand landmarks.\"\"\"\n",
    "    # Images and labels.\n",
    "    images = [image.numpy_view() for image in images]\n",
    "    gestures = [top_gesture for (top_gesture, _) in results]\n",
    "    multi_hand_landmarks_list = [multi_hand_landmarks for (_, multi_hand_landmarks) in results]\n",
    "\n",
    "    # Auto-squaring: this will drop data that does not fit into square or square-ish rectangle.\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images) // rows\n",
    "\n",
    "    # Size and spacing.\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot=(rows,cols, 1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
    "\n",
    "    # Display gestures and hand landmarks.\n",
    "    for i, (image, gestures) in enumerate(zip(images[:rows*cols], gestures[:rows*cols])):\n",
    "        title = f\"{gestures.category_name} ({gestures.score:.2f})\"\n",
    "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols) * 40 + 3\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        for hand_landmarks in multi_hand_landmarks_list[i]:\n",
    "          hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "          hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "          ])\n",
    "\n",
    "          mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        subplot = display_one_image(annotated_image, title, subplot, titlesize=dynamic_titlesize)\n",
    "\n",
    "    # Layout.\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()"
   ],
   "id": "54601c0e7d2b3997",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:25.643720Z",
     "start_time": "2024-04-23T17:43:25.384479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_options = python.BaseOptions(model_asset_path='gesture_recognizer.task')\n",
    "options = vision.GestureRecognizerOptions(base_options=base_options)\n",
    "recognizer = vision.GestureRecognizer.create_from_options(options)"
   ],
   "id": "85486e92a9702a09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713894205.424368       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-22.5.10), renderer: Intel(R) Iris(TM) Plus Graphics 655\n",
      "W0000 00:00:1713894205.448958       1 gesture_recognizer_graph.cc:129] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleration to Xnnpack.\n",
      "I0000 00:00:1713894205.462267       1 hand_gesture_recognizer_graph.cc:250] Custom gesture classifier is not defined.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:43:25.765085Z",
     "start_time": "2024-04-23T17:43:25.645701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "images = []\n",
    "results = []\n",
    "for image_file_name in IMAGE_FILENAMES[:1]:\n",
    "  # STEP 3: Load the input image.\n",
    "  image = mp.Image.create_from_file(image_file_name)\n",
    "\n",
    "  # STEP 4: Recognize gestures in the input image.\n",
    "  recognition_result = recognizer.recognize(image)\n",
    "  print(\"Recognizer result: \", recognition_result)\n",
    "\n",
    "  # STEP 5: Process the result. In this case, visualize it.\n",
    "  images.append(image)\n",
    "  top_gesture = recognition_result.gestures[0][0]\n",
    "  hand_landmarks = recognition_result.hand_landmarks\n",
    "  results.append((top_gesture, hand_landmarks))\n",
    "\n"
   ],
   "id": "eab1eadcea6808ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizer result:  GestureRecognizerResult(gestures=[[Category(index=-1, score=0.7730880379676819, display_name='', category_name='Thumb_Down')]], handedness=[[Category(index=0, score=0.9903218746185303, display_name='Right', category_name='Right')]], hand_landmarks=[[NormalizedLandmark(x=0.3775796592235565, y=0.4484468698501587, z=-7.658888421246957e-07, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.45659855008125305, y=0.5906875729560852, z=-0.12274359911680222, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.5610436201095581, y=0.7097854614257812, z=-0.21682056784629822, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6087026596069336, y=0.8151220083236694, z=-0.296338826417923, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6378511190414429, y=0.908829927444458, z=-0.35788753628730774, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.8904979825019836, y=0.6001406311988831, z=-0.19998541474342346, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7954009175300598, y=0.6598494052886963, z=-0.3039839267730713, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6656880378723145, y=0.6365615129470825, z=-0.335548996925354, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6671821475028992, y=0.6085880398750305, z=-0.35445836186408997, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.898669421672821, y=0.5096270442008972, z=-0.19526363909244537, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.75278240442276, y=0.5814493298530579, z=-0.2936910390853882, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.612981379032135, y=0.5601851940155029, z=-0.3004629611968994, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6546536087989807, y=0.5412085056304932, z=-0.30732816457748413, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.8554795980453491, y=0.4279521703720093, z=-0.20076903700828552, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7269594669342041, y=0.4955122172832489, z=-0.2942810356616974, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6094602346420288, y=0.4916418492794037, z=-0.26329225301742554, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6465423703193665, y=0.47868800163269043, z=-0.24249880015850067, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.7972978353500366, y=0.35576874017715454, z=-0.21797560155391693, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6930086612701416, y=0.40036165714263916, z=-0.27921369671821594, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6115598678588867, y=0.4121805429458618, z=-0.2648589015007019, visibility=0.0, presence=0.0), NormalizedLandmark(x=0.6311843395233154, y=0.40035271644592285, z=-0.25259679555892944, visibility=0.0, presence=0.0)]], hand_world_landmarks=[[Landmark(x=-0.064763642847538, y=-0.017017975449562073, z=0.06780189275741577, visibility=0.0, presence=0.0), Landmark(x=-0.05397053062915802, y=0.011823214590549469, z=0.04478703811764717, visibility=0.0, presence=0.0), Landmark(x=-0.04683179780840874, y=0.040575575083494186, z=0.029534997418522835, visibility=0.0, presence=0.0), Landmark(x=-0.03718922287225723, y=0.06816957145929337, z=0.010855120606720448, visibility=0.0, presence=0.0), Landmark(x=-0.028811821714043617, y=0.08923638612031937, z=-0.0046515981666743755, visibility=0.0, presence=0.0), Landmark(x=0.003516203723847866, y=0.02164996787905693, z=0.005434942431747913, visibility=0.0, presence=0.0), Landmark(x=-0.009741312824189663, y=0.03096579574048519, z=-0.016693249344825745, visibility=0.0, presence=0.0), Landmark(x=-0.023048100993037224, y=0.030053628608584404, z=-0.00359353912062943, visibility=0.0, presence=0.0), Landmark(x=-0.02573326975107193, y=0.021429238840937614, z=0.01740766316652298, visibility=0.0, presence=0.0), Landmark(x=0.005610039457678795, y=0.0008253835840150714, z=0.0033896933309733868, visibility=0.0, presence=0.0), Landmark(x=-0.009612093679606915, y=0.014455408789217472, z=-0.02695797011256218, visibility=0.0, presence=0.0), Landmark(x=-0.03230899199843407, y=0.013932115398347378, z=-0.01494546327739954, visibility=0.0, presence=0.0), Landmark(x=-0.02503972500562668, y=0.006500501185655594, z=0.017695505172014236, visibility=0.0, presence=0.0), Landmark(x=0.0009548654779791832, y=-0.01596050336956978, z=-0.0030519538559019566, visibility=0.0, presence=0.0), Landmark(x=-0.018127020448446274, y=-0.005495800636708736, z=-0.024448638781905174, visibility=0.0, presence=0.0), Landmark(x=-0.03601545840501785, y=-0.003167996183037758, z=-0.009373841807246208, visibility=0.0, presence=0.0), Landmark(x=-0.030271466821432114, y=-0.005923649296164513, z=0.017355477437376976, visibility=0.0, presence=0.0), Landmark(x=-0.013137375004589558, y=-0.03542285040020943, z=-0.003908922895789146, visibility=0.0, presence=0.0), Landmark(x=-0.020970936864614487, y=-0.024763792753219604, z=-0.018909649923443794, visibility=0.0, presence=0.0), Landmark(x=-0.034383516758680344, y=-0.02049766480922699, z=-0.012046878226101398, visibility=0.0, presence=0.0), Landmark(x=-0.03402365744113922, y=-0.025127427652478218, z=0.0032980097457766533, visibility=0.0, presence=0.0)]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:57:14.400318Z",
     "start_time": "2024-04-23T17:57:14.384843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BreakException(Exception):\n",
    "    pass\n",
    "def analyse_image(image):\n",
    "    recognition_result = recognizer.recognize(image)\n",
    "    landmarks = recognition_result.hand_landmarks\n",
    "    # paint dots at hand landmarks\n",
    "    img = np.copy(image.numpy_view())\n",
    "    for outer_landmark in landmarks:\n",
    "        for landmark in outer_landmark:\n",
    "            cv2.circle(img, (int(landmark.x * image.width), int(landmark.y * image.height)), 5, (255, 255, 255), 5)\n",
    "    cv2.imshow(\"GestureGlide\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        raise BreakException()\n"
   ],
   "id": "30f36749afc0e64e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:57:25.426580Z",
     "start_time": "2024-04-23T17:57:15.044743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        try:\n",
    "            success, frame = capture.read()\n",
    "            if success:\n",
    "                frame_uint8 = np.array(frame, dtype=np.uint8)\n",
    "                image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_uint8)\n",
    "                analyse_image(image)\n",
    "            else:\n",
    "                print(\"Critical error\")\n",
    "                exit(1)\n",
    "        except (KeyboardInterrupt, BreakException):\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "except Exception as e:\n",
    "    cv2.destroyAllWindows()\n",
    "    raise e\n"
   ],
   "id": "5b0ab58113262bff",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:44:43.760892Z",
     "start_time": "2024-04-23T17:44:43.758035Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "355c4346325f150a",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
